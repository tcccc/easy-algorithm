//rbt，红黑树

//首先红黑树也是二叉树的一种
//与AVL树一样，红黑树比二叉树多了许多规则
//回忆一下AVL树，它是依靠平衡因子即所谓的高度来维持 自身的平衡的
//红黑树的意义与AVL树一样，是为了打破普通二叉树可能会退化成线性单链表的可能性
//既然是为了查找效率高，那么它很自然的也是一颗平衡二叉树
//红黑树的平衡性是不如AVL树的，这意味着，它的查询效率比AVL树要低一些
//同样的有缺点肯定要有优点，不然没有存在的意义了，红黑树的插入与删除的效率比AVL树要高

//一个写法优秀的AVL树(注意是写法优秀，有些情况不需要回溯到根节点）的插入和删除的效率在大量数据的支持下，可以看出只比rbt略低一些，
//同样的查询效率也只比rbt略高
//当你需要一个二叉树数据结构时，倾向于哪个方面就选取哪种平衡二叉树，虽然基本需要平衡二叉树的地方都选择了红黑树，我没搞清楚为什么。
//可能在那些场景下查询操作并不如插入与删除操作做的次数多，亦或红黑树更稳定些？

rbtree的定义，符合以下几点的二叉树就是红黑树.
1.每个节点只能为黑色或红色
2.红色节点必须要有2个黑色子节点
3.根节点为黑色
4.叶子为null，为黑色节点
5.每个节点到其各个叶子的路径上包含相同个数的黑色节点

// 现在有个问题，我们知道红黑树是平衡树对吧，为什么？ 
//根据这些性质推导出红黑树是一个平衡树，以此来保证我们的查询操作效率在O(log2n)级别
//推导过程有些麻烦，主要是涉及了合并操作

//分析存在多少黑色节点的叶子， 很显然是n+1，原因是插入一个节点必然另原树失去一个黑色的叶子，而插入的节点又会带来2个黑色的叶子
//所以很明显了，2-1=1，这意味插入一个节点就会多一个叶子，所以总共有n+1个叶子，你也可以用归纳法来推导

//假设红黑树的高度为h， 我们现在进行合并操作，把所有红色节点与它的父节点合并，最多有n/2个红色节点对吧，最终合并成一个2-3-4树，设高度为h'
//    h/2>=h'   ，这里引入一个黑高度的概念，从此节点向叶子走，经过多少黑节点黑高度就是多少，不包含他自己
//  合并后2-3-4数，他的高度应是他的黑高度，而黑高度>=h/2
//现在考虑一个2-3-4树有多少个叶子?  不需要一个准确数，只需要一个范围，从分支数的思路来看，至多有 4的h'次幂个叶子，最多4个分支
//至少有2的h'次幂个叶子，至少2个分支，在根据前面推出的n+1，我们得出     2的h'次幂<= n+1 <=4的h'次幂
//所以   h'<=log2(n+1)，  再根据 h/2<=h'
//最终推出   h<=2log2(n+1)    证明了红黑树的高度是log2n级别的



